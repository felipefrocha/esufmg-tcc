% -----------------------------------------------------------------------------
% Metodologia
% -----------------------------------------------------------------------------

\chapter{Metodologia}
\label{chap:metodologia}
\section{Disponibilidade dos recursos deste trabalho}
Todos os componentes definidos nesse trabalho estarão contidos em um ou mais repositórios públicos, garantindo assim a livre apreciação da comunidade não só científica, mas a todos os interessados na contribuição ou utilização sob a licença pública geral GNU versão 3 \cite{foss2022}.

\section{Especificação dos nós integrantes cluster de baixo custo}

A formação do cluster será de máquinas virtuais (VMs) e/ou físicas que possuem custo e capacidade computacionais mais baixos, com configurações comumente encontradas em computadores do tipo desktops, como os utilizados em residências, escritórios e laboratórios de informática genéricos.

A primeira versão dessa solução será realizada de maneira simulada, utilizando ambiente virtualizado com VMs que por sua vez serão provisionadas em hypervisors do tipo 2 \cite{comer_cloud_2021} (\emph{hosted hypervisor}), para garantir a simplicidade da implementação da primeira fase (TCC 1) e validar o conceito de provisionamento, configuração e \emph{deploy} de aplicações testes, bem como laboratório das ferramentas de monitoramento que serão utilizadas, a serem descritas a seguir. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{04-figuras/vms.png}
    \caption{Hosted Hypervisor diagrama representativo de componentes (Fonte: Google Images, 2021)}
    \label{fig:vms}
\end{figure}

A versão final do projeto (ambas no TCC II) visa o provisionamento do cluster nos ambientes de teste configurados como descrito anteriormente, sendo que algumas premissas serão utilizadas, como o uso de mesmo sistema operacional e versão do mesmo em cada um desses computadores. Garantindo a redução de configuração necessária para a implementação. Outra premissa utilizada para esse estudo, será a utilização de uma rede comum aos computadores. 

O aproveitamento de computadores comuns já existentes e subutilizados seja por uso abaixo de sua capacidade ou ainda intervalos de ociosidade, qualifica o baixo custo da formação do cluster em questão, apresentando CAPEX (capital expenditure),  ou investimento inicial mínimo, se não zero, necessitando da interdisciplinaridade sugerida e defendida dentro das instituições para o qual esse trabalho intenta apresentar uma alternativa.

\section{Plataforma de orquestração de carga de trabalho}

A plataforma de cluster e orquestração de cargas de trabalho utilizadas nesse trabalho será o Kubernetes. A arquitetura de implementação do cluster será de multi-master com etcd \cite{etcd2022} (controlador de logs, e estado do cluster) atachado \cite{kubernetes2022}, ou rodando nos mesmo computadores masters do cluster. 
Essa arquitetura recomendada, garante a alta disponibilidade do cluster importante para que não haja interrupções inesperadas durante a orquestração das cargas de trabalho (execução, disponibilidade e garantia de estado desejado). Apenas não garantindo uma recuperação rápida de outages dos nós mestres, significando a perda de todos os estados e, com isso, havendo a necessidade de reconfiguração do cluster. Porém considerando os recursos limitados, na justificativa desse projeto, a alta disponibilidade de estado, significaria na obrigatoriedade do mesmo número de computadores disponibilizados para etcd e masters para controle dos estados.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{04-figuras/kubeadm-ha-topology-stacked-etcd.png}
    \caption{Kubernetes Arquitetura de alta disponibilidade (Fonte: The Linux Foundation\textregistered, 2021)}
    \label{fig:kubeadmha}
\end{figure}


Toda a implementação da solução e os componentes relacionados serão conteinerizados, possibilitando  sua orquestração pelo cluster de Kubernetes\textregistered. Apenas as configurações dos clusters em si e seu provisionamento não estarão conteinerizados. Esses serão disponibilizados em outro repositório específico. 
Para ciclo de vida da aplicação e configurações gerais da solução será utilizado uma estratégia de organização de código em monorepo, facilitando a visualização, centralização, sincronização, padronização como benefícios primários e demonstrados na literatura reforçando a adoção dessa estratégia \cite{brito_monorepos_2018}.
\section{Configuração e provisionamento do cluster}
Para provisionamento do \emph{cluster} utilizaremos Ansible\textregistered da empresa RedHat\textregistered. Sua adoção se deu pela característica minimalista de configuração inicial, facilidade de uso e uma característica fundamental que diminui o \emph{overhead} de operação necessária para sua utilização, não possuir agente instalado nas no inventário de máquinas gerenciadas. 

O principal ganho em existente no uso de um sistema de gerenciamento de configuração (CMS) é o não gerenciamento do sistema para utilizá-lo, não há necessidade de configuração ou instalação de nenhum binário específico para sua utilização, reduzindo assim a complexidade de utilização inicial.

A configuração inicial é realizada pela disponibilidade de acesso via rede, python na máquina a ter sua configuração gerenciada (asset, ou recurso) e por meio de alguns tipos de autenticação (kerberos, WinRM, SSH etc), sendo no caso utilizado o protocolo SSH \cite{noauthor_rfc4254_nodate} por chaves assimétricas o que garante um nível aceitável de segurança, especialmente quando se é possível escolher os algoritmos de criptografia e suas possíveis variações como RSA e ED25519.

\section{Análise de dados}

O banco de dados “Vendas de Medicamentos Controlados e Antimicrobianos - Medicamentos Industrializados”, disponibilizado pelo governo brasileiro (via portal dados.gov.b), será utilizado nesse trabalho. Os anos correspondentes dos dados são no período entre 2014 e 2021 e o banco possui mais de 70 GB  e mais de 530 milhões de linhas, sendo assim suficiente para ser utilizado como carga de trabalho ao se calcular uma regressão linear para consumo do medicamento de azitromicina.
Como caso base para comparação e teste do modelo proposto, em termos de tempo para processamento da análise proposta acima,  utilizaremos um único computador (desktop) com capacidade equivalente a 8 computadores de menor capacidade (1vCPU e 2GB De RAM) designados com nós do cluster, portanto contendo recursos de  8 vCPUs e 16GB de RAM. 

\section{Monitoramento}

Serão utilizados para monitoramento de execução das cargas de trabalho Prometheus\textregistered  e para visualização dos dados Grafana\textregistered, ambos sendo configurados a partir do provisionamento do cluster, ainda com a ferramenta proposta inicialmente Ansible\textregistered. Dessa forma será possível avaliar parâmetros de taxa de lotação das máquinas base, pelo parâmetro de processador e memória, operações de leitura e escrita no disco e também tráfego de rede. Por meio dessas ferramentas será possível ainda, avaliar dados de tempo de execução de cargas de trabalho em ambos os ambientes propostos e assim poder compará-los sob eficiência de uso de hardware.

\section{Comparação entre tipos de virtualização}

A arquitetura do tipo x86 foi o tipo mais comum de arquitetura de computadores e boa parte da tecnologia de virtualização inicialmente foi desenvolvida nessa arquitetura (FAYYA, 2013). Nesse contexto será também utilizado na construção desse trabalho virtualizações com guest e host OS  em x86, para garantir que outros estudos possam ser relacionados na obtenção dos resultados desse trabalho.
Como descrito anteriormente, serão utilizadas maquinas virtuais com 2GB de RAM e containers com limitações de mesmo tamanho para a realização de configuração do cluster nesses ambientes, e a partir destes a execução dos workloads.

O tipo de teste de aplicação será um macrobenchmark (system level benchmark) \cite{huge2008,scheepers2014virtualization} comparando parâmetros de uso de CPU, memória e tempo de execução da carga de trabalho proposta na sessão 3.1.5 deste trabalho. Os parâmetros serão avaliados  tanto na máquina de suporte a virtualização e também nas máquinas virtuais e containers, bem como o tempo provisionamento do container da carga de trabalho, tempo de execução e quantidades de falhas.

Esse método USE (Usage, Saturation and Errors) \cite{greg2022} será utilizado para extrair e apresentar métricas e avaliar possíveis problemas, sendo que esse não é o foco do trabalho, mas captura de forma adequada os parâmetros de hardware citados acima.

Para controle de tempo será por meio de ferramentas de APM (Application Performance Management) associada a aplicação da carga de trabalho. Dessa forma garantimos a avaliação de qualidade e possíveis problemas, tempos de execução dentre outros possíveis problemas e métricas de performance da aplicação \cite{tang2021systematical}.


\section{Cronograma}
A primeira parte do Trabalho de Conclusão de Curso consiste em um estudo dos métodos de virtualização, plataformas elegidas como possíveis soluções e a composição de arquitetura da plataforma de orquestração das cargas de trabalho. Bem como a construção de um modelo inicial de assim como a definição de uma arquitetura de referência a ser refinada no TCC II junto aos demais diagramas do sistema. A solução proposta para realizar tanto a orquestração como também a comparação das cargas de trabalho também serão validadas durante a execução do TCC II.
Na \ref{fig:cronograma} é apresentado o cronograma total:

\begin{landscape}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{04-figuras/TCC cronograma - Sheet1.pdf}
    \caption{Cronograma geral do trabalho}
    \label{fig:cronograma}
\end{figure}
\end{landscape}